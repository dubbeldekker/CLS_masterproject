{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "975686d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47f9867d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20190904_RippleF2_spk2_d02.dat' '20190904_Vocalization_spk2_d02.dat'\n",
      " '20190828_RippleF2_d02.dat' '20190828_Vocalization_d02.dat'\n",
      " '20190409_Ripple2_d01.dat' '20190409_Vocalization_d01.dat'\n",
      " '20190125_Ripple2_d01.dat' '20190125_Vocalization_d01.dat'\n",
      " '20180807_Ripple2_d01.dat' '20180807_Vocalization_d01.dat'\n",
      " '20180727_Ripple2_d01.dat' '20180727_Vocalization_d01.dat']\n"
     ]
    }
   ],
   "source": [
    "#make list of all datasets \n",
    "dates = [\"20190904\", \"20190828\", \"20190409\", \"20190125\", \"20180807\", \"20180727\"]\n",
    "files = os.listdir(\"C:/Users/marij/Documents/studie/CLS/Masterproject/data_processing/data_kilosort\") #kilosort output folder\n",
    "#print(files)\n",
    "file_list = []\n",
    "\n",
    "for i in dates: #extract wanted files out of the folder\n",
    "    file_list.append([file for file in files if i in file])\n",
    "    \n",
    "file_list = np.array(file_list).flatten()\n",
    "\n",
    "bins = [str(1), str(5), str(10), str(15), str(20), str(30), str(40), str(50)]\n",
    "voc_suffix = [\"\", \"_allvoc\", \"_baseline\", \"_baseline_voclen\", \"_first_half_voc\", \"_second_half_voc\", \"_startvoc\", \"_endvoc\"]\n",
    "voc_cols = [\"whole\", \"all_voc\", \"baseline_whole\", \"baseline_voclen\",\"first_half\", \"second_half\", \"first_100ms\", \"last_100ms\"]\n",
    "trials = 5\n",
    "vocs = 18\n",
    "minutes = 5\n",
    "parts = 2\n",
    "\n",
    "folder_path = 'C:/Users/marij/Documents/studie/CLS/Masterproject/data_processing/data_binarization/'\n",
    "save_folder = \"C:/Users/marij/Documents/studie/CLS/Masterproject/RESULTS/data_information/\"\n",
    "#file_list = file_list[[10, 11]]\n",
    "print(file_list)\n",
    "#bins = [str(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f68dcbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  16\n",
      "Ripple file:  20190904_RippleF2_spk2_d02.dat\n",
      "           whole  minute   part1   part2\n",
      "bin (ms)                                \n",
      "1         756569  119974  301395  301399\n",
      "5         151314   23996   60280   60280\n",
      "10         75657   11999   30141   30140\n",
      "15         50438    8000   20094   20094\n",
      "20         37829    6001   15071   15070\n",
      "30         25219    4001   10048   10047\n",
      "40         18915    3001    7536    7535\n",
      "50         15132    2402    6029    6029\n",
      "n =  17\n",
      "vocalization file:  20190904_Vocalization_spk2_d02.dat\n",
      "           whole  all_voc  baseline_whole  baseline_voclen  first_half  \\\n",
      "bin (ms)                                                                 \n",
      "1         616060   109189          504795           109189       54569   \n",
      "5         123212    21909          101027            21914       10930   \n",
      "10         61606    11000           50564            11004        5477   \n",
      "15         41071     7364           33738             7363        3660   \n",
      "20         30803     5545           25327             5542        2750   \n",
      "30         20536     3727           16916             3727        1841   \n",
      "40         15402     2818           12712             2816        1383   \n",
      "50         12322     2272           10184             2272        1113   \n",
      "\n",
      "          second_half  first_100ms  last_100ms  trial1  trial2  ...  voc9  \\\n",
      "bin (ms)                                                        ...         \n",
      "1               54620         9090        9090   93185   93209  ...  5325   \n",
      "5               10979         1890        1890   18638   18643  ...  1070   \n",
      "10               5523          990         990    9319    9322  ...   536   \n",
      "15               3704          687         687    6214    6215  ...   360   \n",
      "20               2795          540         540    4660    4661  ...   271   \n",
      "30               1886          393         393    3107    3108  ...   182   \n",
      "40               1435          314         314    2330    2331  ...   137   \n",
      "50               1159          270         270    1865    1865  ...   111   \n",
      "\n",
      "          voc10  voc11  voc12  voc13  voc14  voc15  voc16  voc17  voc18  \n",
      "bin (ms)                                                                 \n",
      "1          8538   7478   5555  10394   4428   3590   3699   5262   5896  \n",
      "5          1712   1500   1115   2084    890    721    744   1056   1183  \n",
      "10          859    754    560   1044    449    362    375    531    595  \n",
      "15          575    503    375    698    300    244    250    355    398  \n",
      "20          433    379    284    525    225    183    190    269    300  \n",
      "30          290    254    190    352    153    125    126    180    201  \n",
      "40          219    193    145    265    115     94     98    137    152  \n",
      "50          175    155    116    212     94     76     79    110    122  \n",
      "\n",
      "[8 rows x 31 columns]\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:/Users/marij/Documents/studie/CLS/Masterproject/RESULTS/data_information/20190904_vocalization.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-845d558c5d20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;31m#f.write(column_names_text)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;31m#f.write(\"\\n\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtextfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m     \u001b[1;31m#f.close()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3385\u001b[0m         )\n\u001b[0;32m   3386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3387\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3388\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3389\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1081\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         )\n\u001b[1;32m-> 1083\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1085\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \"\"\"\n\u001b[0;32m    227\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:/Users/marij/Documents/studie/CLS/Masterproject/RESULTS/data_information/20190904_vocalization.txt'"
     ]
    }
   ],
   "source": [
    "for dataset in file_list:\n",
    "    path = folder_path + dataset + '/'\n",
    "    date = dataset[0:8]\n",
    "    \n",
    "    neuron_file = path + date + '_neuronlabels.txt'\n",
    "    neurons = pd.read_csv(neuron_file, header = None, names = ['id', 'channel'])\n",
    "    neurons_id = neurons['id'].to_numpy().flatten()\n",
    "    neurons_channel = neurons['channel'].to_numpy().flatten()\n",
    "    n = len(neurons)\n",
    "    print('n = ', n)\n",
    "    \n",
    "    df = pd.DataFrame(index = bins)\n",
    "    df.index.name = \"bin (ms)\"\n",
    "    if \"Vocalization\" in dataset:\n",
    "        print(\"vocalization file: \", dataset)\n",
    "        save_suffix = date + \"_vocalization\"\n",
    "        for data_type in range(len(voc_suffix)):\n",
    "            bin_N = []\n",
    "            for binsec in bins:\n",
    "                #path to datafile\n",
    "                data_path = path + date + '_binsec' + str(binsec) + voc_suffix[data_type] + '.dat'\n",
    "                #print(data_path)\n",
    "                data_strings = np.loadtxt(data_path, dtype=str)\n",
    "                #get N\n",
    "                N = data_strings.shape[0]\n",
    "                bin_N.append(N)\n",
    "            df[voc_cols[data_type]] = bin_N\n",
    "        \n",
    "        for trial in range(trials):\n",
    "            bin_N = []\n",
    "            for binsec in bins:\n",
    "                #path to datafile\n",
    "                cut_path = path + \"cut_binarized_data\" + binsec + '/'\n",
    "                data_path = cut_path + date + '_binsec' + str(binsec) + \"_trial\" + str(trial+1) + '.dat'\n",
    "                #print(data_path)\n",
    "                data_strings = np.loadtxt(data_path, dtype=str)\n",
    "                #get N\n",
    "                N = data_strings.shape[0]\n",
    "                bin_N.append(N)\n",
    "            col_title = \"trial\" + str(trial+1)\n",
    "            df[col_title] = bin_N\n",
    "        \n",
    "        for voc in range(vocs):\n",
    "            bin_N = []\n",
    "            for binsec in bins:\n",
    "                #path to datafile\n",
    "                cut_path = path + \"cut_binarized_data\" + binsec + '/'\n",
    "                data_path = cut_path + date + '_binsec' + str(binsec) + \"_voc\" + str(voc+1) + '.dat'\n",
    "                #print(data_path)\n",
    "                data_strings = np.loadtxt(data_path, dtype=str)\n",
    "                #get N\n",
    "                N = data_strings.shape[0]\n",
    "                bin_N.append(N)\n",
    "            col_title = \"voc\" + str(voc+1)\n",
    "            df[col_title] = bin_N\n",
    "            \n",
    "    elif \"Ripple\" in dataset:\n",
    "        print(\"Ripple file: \", dataset)\n",
    "        save_suffix = date + \"_ripple\"\n",
    "        bin_N = []\n",
    "        for binsec in bins:\n",
    "            #path to datafile\n",
    "            data_path = path + date + '_binsec' + str(binsec) + '.dat'\n",
    "            #print(data_path)\n",
    "            data_strings = np.loadtxt(data_path, dtype=str)\n",
    "            #get N\n",
    "            N = data_strings.shape[0]\n",
    "            bin_N.append(N)\n",
    "        df[\"whole\"] = bin_N\n",
    "        \n",
    "        for minute in range(minutes):\n",
    "            bin_N = []\n",
    "            for binsec in bins:\n",
    "                #path to datafile\n",
    "                cut_path = path + \"cut_binarized_data\" + binsec + '/'\n",
    "                data_path = cut_path + date + '_binsec' + str(binsec) + \"_minute\" + str(minute+1) + '.dat'\n",
    "                #print(data_path)\n",
    "                data_strings = np.loadtxt(data_path, dtype=str)\n",
    "                #get N\n",
    "                N = data_strings.shape[0]\n",
    "                bin_N.append(N)\n",
    "            col_title = \"minute\" + str(minute+1)\n",
    "            df[col_title] = bin_N\n",
    "        \n",
    "        for part in range(parts):\n",
    "            bin_N = []\n",
    "            for binsec in bins:\n",
    "                #path to datafile\n",
    "                cut_path = path + \"cut_binarized_data\" + binsec + '/'\n",
    "                data_path = cut_path + date + '_binsec' + str(binsec) + \"_ripple\" + str(part+1) + '.dat'\n",
    "                #print(data_path)\n",
    "                data_strings = np.loadtxt(data_path, dtype=str)\n",
    "                #get N\n",
    "                N = data_strings.shape[0]\n",
    "                bin_N.append(N)\n",
    "            col_title = \"part\" + str(part+1)\n",
    "            df[col_title] = bin_N\n",
    "    else:\n",
    "        print(\"weird dataset\")\n",
    "    print(df)\n",
    "    #make save_path\n",
    "    save_path = save_folder + save_suffix\n",
    "    textfile = save_path + '.txt'\n",
    "    #f = open(textfile, 'w')\n",
    "    #f.write(dataset)\n",
    "    #f.write('\\n')\n",
    "    #fwrite = \"n = \" + str(n) + \"\\n\"\n",
    "    #f.write(fwrite)\n",
    "    #column_names = df.columns.values.tolist()\n",
    "    #column_names = [\"bin(ms)\"] + column_names\n",
    "    #column_names_text = ','.join(column_names)\n",
    "    #f.write(column_names_text)\n",
    "    #f.write(\"\\n\")\n",
    "    df.to_csv(textfile, mode='w', header = True, index = True)\n",
    "    #f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
